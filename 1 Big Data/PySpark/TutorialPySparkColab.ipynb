{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbRRaZlBt6Nh"
      },
      "source": [
        "# Tutorial 1: Configuración y carga de datos en PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Iv32T_kgRf"
      },
      "source": [
        "##Paso 1: Configuración del entorno de PySpark en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "sKfMHXDwiZqF",
        "outputId": "4ac2f65b-4c18-4cec-e276-deb968f55222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [913 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,545 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,990 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,322 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,422 kB]\n",
            "Fetched 11.5 MB in 2s (4,835 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "20 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 51 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 66.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=4773cdecc746bad2102b976d5f5a68884924684371d25f828282162b549cd752\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.2.2-bin-hadoop3.2'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Bibliotecas para poder trabajar con Spark\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.2-bin-hadoop3.2.tgz  \n",
        "#Configuración de Spark con Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "#Estableciendo variable de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.2-bin-hadoop3.2\"\n",
        "\n",
        "#Buscando e inicializando la instalación de Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-DE0eskkyRA"
      },
      "source": [
        "##Paso 2: Selección y vista de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ywqxFXoXJiv0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('sample_data/california_housing_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "jH2hpm6PJYUK",
        "outputId": "6b2dc0aa-fb7c-49a8-e3c2-f24fe205da1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9c849fef-73c7-4d89-86ef-0628554be142\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.05</td>\n",
              "      <td>37.37</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3885.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>1537.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>6.6085</td>\n",
              "      <td>344700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-118.30</td>\n",
              "      <td>34.26</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1510.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>809.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>3.5990</td>\n",
              "      <td>176500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-117.81</td>\n",
              "      <td>33.78</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3589.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>495.0</td>\n",
              "      <td>5.7934</td>\n",
              "      <td>270500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-118.36</td>\n",
              "      <td>33.82</td>\n",
              "      <td>28.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.1359</td>\n",
              "      <td>330000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-119.67</td>\n",
              "      <td>36.33</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>2.9375</td>\n",
              "      <td>81700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>-119.86</td>\n",
              "      <td>34.42</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1450.0</td>\n",
              "      <td>642.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>607.0</td>\n",
              "      <td>1.1790</td>\n",
              "      <td>225000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>-118.14</td>\n",
              "      <td>34.06</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5257.0</td>\n",
              "      <td>1082.0</td>\n",
              "      <td>3496.0</td>\n",
              "      <td>1036.0</td>\n",
              "      <td>3.3906</td>\n",
              "      <td>237200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-119.70</td>\n",
              "      <td>36.30</td>\n",
              "      <td>10.0</td>\n",
              "      <td>956.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>693.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>2.2895</td>\n",
              "      <td>62000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>-117.12</td>\n",
              "      <td>34.10</td>\n",
              "      <td>40.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.2708</td>\n",
              "      <td>162500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>-119.63</td>\n",
              "      <td>34.42</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1765.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>753.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>8.5608</td>\n",
              "      <td>500001.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c849fef-73c7-4d89-86ef-0628554be142')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c849fef-73c7-4d89-86ef-0628554be142 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c849fef-73c7-4d89-86ef-0628554be142');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -122.05     37.37                27.0       3885.0           661.0   \n",
              "1       -118.30     34.26                43.0       1510.0           310.0   \n",
              "2       -117.81     33.78                27.0       3589.0           507.0   \n",
              "3       -118.36     33.82                28.0         67.0            15.0   \n",
              "4       -119.67     36.33                19.0       1241.0           244.0   \n",
              "...         ...       ...                 ...          ...             ...   \n",
              "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
              "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
              "2997    -119.70     36.30                10.0        956.0           201.0   \n",
              "2998    -117.12     34.10                40.0         96.0            14.0   \n",
              "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
              "\n",
              "      population  households  median_income  median_house_value  \n",
              "0         1537.0       606.0         6.6085            344700.0  \n",
              "1          809.0       277.0         3.5990            176500.0  \n",
              "2         1484.0       495.0         5.7934            270500.0  \n",
              "3           49.0        11.0         6.1359            330000.0  \n",
              "4          850.0       237.0         2.9375             81700.0  \n",
              "...          ...         ...            ...                 ...  \n",
              "2995      1258.0       607.0         1.1790            225000.0  \n",
              "2996      3496.0      1036.0         3.3906            237200.0  \n",
              "2997       693.0       220.0         2.2895             62000.0  \n",
              "2998        46.0        14.0         3.2708            162500.0  \n",
              "2999       753.0       260.0         8.5608            500001.0  \n",
              "\n",
              "[3000 rows x 9 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px0CvEobk43I"
      },
      "source": [
        "## Paso 3: Crear la sesión de trabajo de Spark\n",
        "\n",
        "Ya seleccionado y visto el conjunto de datos comencemos a trabajar con PySpark. Para comenzar a trabajar con PySpark, debemos iniciar la sesión de Spark. Para esto realizaremos lo siguiente:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Importar SparkSession \n",
        "2.   Crear la sesión \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "hqEN5b1eKRTn",
        "outputId": "eb9717e9-8f0d-4ce8-91bd-621736774e4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b5e0aa9acb28:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_prueba1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2380cee150>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Verificar la funcionalidad de Pyspark \n",
        "from pyspark.sql import SparkSession\n",
        "spark_session = SparkSession.builder.appName('PySpark_prueba1').getOrCreate()\n",
        "spark_session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbRahpVtmPBu"
      },
      "source": [
        "La SparkSession contiene los siguiente elementos:\n",
        "\n",
        "\n",
        "*   Version: La versión de Spark\n",
        "*   Master: Como estamos trabajando en un sistema en la nube pero no distribuido nos devuelve local, sin embargo, si tuvieramos un sistema distribuido aquí entonces podríamos tener diferentes clústeres, así como primero habrá un maestro y luego una estructura similar a un árbol (cluster_1, cluster_2 ... cluster_n).\n",
        "*   AppName: Nombre de la aplicación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iADBYL1_tvfU"
      },
      "source": [
        "##Paso 4: Cargar los datos para manipularlos dentro de Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJdqDvH1Ke0F",
        "outputId": "4b2083ea-943e-4289-8cbe-2c57e7b4c5e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_spark = spark_session.read.csv('sample_data/california_housing_train.csv')\n",
        "df_spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkNMWmBnm6QO"
      },
      "source": [
        "En el caso de PySpark para visualizar los datos tenemos la función *show()* ques similar a *head()* de pandas con algunas diferencias como:\n",
        "\n",
        "\n",
        "1.   Mostrar 20 registro en lugar de 5\n",
        "2.   La apariencia de los datos\n",
        "3.   En lugar de tomar la primera fila como encabezados la incluye como un registro y coloca _c1 a _cn como nombre de la columna.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT2_YaGFnynL",
        "outputId": "c8ccd6d8-6819-4f83-a120-1d5ea0730d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|        _c0|      _c1|               _c2|        _c3|           _c4|        _c5|        _c6|          _c7|               _c8|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n",
            "|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n",
            "|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n",
            "|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n",
            "|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n",
            "|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n",
            "|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n",
            "|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n",
            "|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n",
            "|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n",
            "|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n",
            "|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n",
            "|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoQGO2FxmtNK"
      },
      "source": [
        "Si queremos integrar la primera fila como los nombres de las columnas hay que agregar una opción a la hora de cargar los datos en el DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37zvYB-onzJt",
        "outputId": "c9980da1-c4d6-4c94-cb54-b88c690d41bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[longitude: string, latitude: string, housing_median_age: string, total_rooms: string, total_bedrooms: string, population: string, households: string, median_income: string, median_house_value: string]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#La opción option('header','true')\n",
        "df_spark_col  = spark_session.read.option('header', 'true').csv('sample_data/california_housing_train.csv')\n",
        "df_spark_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w52J4vd0oIT4",
        "outputId": "b60f75d5-10b1-4bd7-8ac3-02b84955c1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n",
            "|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n",
            "|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n",
            "|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n",
            "|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n",
            "|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n",
            "|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n",
            "|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n",
            "|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n",
            "|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n",
            "|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n",
            "|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n",
            "|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n",
            "|-114.670000|33.920000|         17.000000|  97.000000|     24.000000|  29.000000|  15.000000|     1.265600|      27500.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark_col.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkGw3U3UpiD7"
      },
      "source": [
        "Como comparativa entre Pandas y PySpark ambos manejan la información dentro de DataFrames pero la función *show()* solo es aplicable en Spark mientras que *head()* funciona en ambos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBoQNiUVoSD4",
        "outputId": "ec81819f-f538-4714-daed-cb22a62664be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "print(type(df_spark_col))\n",
        "print(type(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4l2FDVMqRI3"
      },
      "source": [
        "La función *head()* muestra por cada columna el valor que tiene, sin embargo muestra la información por fila utilizando este formato mencionado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2FAh9QDoha_",
        "outputId": "913147f1-9d94-4f24-8a3b-f438c8592526"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(longitude='-114.310000', latitude='34.190000', housing_median_age='15.000000', total_rooms='5612.000000', total_bedrooms='1283.000000', population='1015.000000', households='472.000000', median_income='1.493600', median_house_value='66900.000000'),\n",
              " Row(longitude='-114.470000', latitude='34.400000', housing_median_age='19.000000', total_rooms='7650.000000', total_bedrooms='1901.000000', population='1129.000000', households='463.000000', median_income='1.820000', median_house_value='80100.000000'),\n",
              " Row(longitude='-114.560000', latitude='33.690000', housing_median_age='17.000000', total_rooms='720.000000', total_bedrooms='174.000000', population='333.000000', households='117.000000', median_income='1.650900', median_house_value='85700.000000'),\n",
              " Row(longitude='-114.570000', latitude='33.640000', housing_median_age='14.000000', total_rooms='1501.000000', total_bedrooms='337.000000', population='515.000000', households='226.000000', median_income='3.191700', median_house_value='73400.000000'),\n",
              " Row(longitude='-114.570000', latitude='33.570000', housing_median_age='20.000000', total_rooms='1454.000000', total_bedrooms='326.000000', population='624.000000', households='262.000000', median_income='1.925000', median_house_value='65500.000000'),\n",
              " Row(longitude='-114.580000', latitude='33.630000', housing_median_age='29.000000', total_rooms='1387.000000', total_bedrooms='236.000000', population='671.000000', households='239.000000', median_income='3.343800', median_house_value='74000.000000'),\n",
              " Row(longitude='-114.580000', latitude='33.610000', housing_median_age='25.000000', total_rooms='2907.000000', total_bedrooms='680.000000', population='1841.000000', households='633.000000', median_income='2.676800', median_house_value='82400.000000'),\n",
              " Row(longitude='-114.590000', latitude='34.830000', housing_median_age='41.000000', total_rooms='812.000000', total_bedrooms='168.000000', population='375.000000', households='158.000000', median_income='1.708300', median_house_value='48500.000000'),\n",
              " Row(longitude='-114.590000', latitude='33.610000', housing_median_age='34.000000', total_rooms='4789.000000', total_bedrooms='1175.000000', population='3134.000000', households='1056.000000', median_income='2.178200', median_house_value='58400.000000'),\n",
              " Row(longitude='-114.600000', latitude='34.830000', housing_median_age='46.000000', total_rooms='1497.000000', total_bedrooms='309.000000', population='787.000000', households='271.000000', median_income='2.190800', median_house_value='48100.000000')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_spark_col.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tNzS6dPrfns"
      },
      "source": [
        "Si queremos saber información acerca de los datos utilizamos la función *printSchema()* la cual muestra el nombre de cada columna, su tipo de dato y si permite valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bdNEtSRokEQ",
        "outputId": "2af9c9b3-2edf-4a19-afa5-99d24b8e8b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- housing_median_age: string (nullable = true)\n",
            " |-- total_rooms: string (nullable = true)\n",
            " |-- total_bedrooms: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            " |-- households: string (nullable = true)\n",
            " |-- median_income: string (nullable = true)\n",
            " |-- median_house_value: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark_col.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-buZtUBtnOp"
      },
      "source": [
        "#Tutorial 2: Consultas en DataFrame dentro de PySpark "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "tgvc4GJCqYPD",
        "outputId": "d8ca084e-d16d-4e1c-eea2-680942804119"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://869aba917921:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>OperacionesFiltrado</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6cdffe2bd0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('OperacionesFiltrado').getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa09MN6CwPEq"
      },
      "source": [
        "Para cargar la información usaremos solamente la función *csv()* pero agregando parámetros de configuración para que tome el primer registro como los nombres de las columnas y tambien que a partir de los datos de entrada infiera el tipo de dato. Si no colocamos esto automáticamente considera de tipo *string* las columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n87v4tRhqpZe",
        "outputId": "627dcc6a-ad1f-4da0-a8ec-c7e894a8b6b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           null|                 null|                 40000|\n",
            "|         null|             34|                   10|                 38000|\n",
            "|         null|             36|                 null|                  null|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark = spark.read.csv('part2.csv', header = True, inferSchema=True)\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4neGDBsyvX-j",
        "outputId": "9979b7a4-36d3-436c-9568-ede8d4f681a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Employee Name: string (nullable = true)\n",
            " |-- Age of Employee: integer (nullable = true)\n",
            " |-- Experience (in years): integer (nullable = true)\n",
            " |-- Salary (per month - $): integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWV3LXYuw0IQ"
      },
      "source": [
        "Si se necesita podemos renombrar las columnas para referirnos a ellas de una forma más sencilla o simplificada con la función *withColumnRenamed()*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr5GDyV93GOi"
      },
      "source": [
        "## Filtros y selección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B5aqNbGrK_2",
        "outputId": "a910c386-b4c3-4202-a733-f0e9f531789e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Salary (per month - $)\",\"EmpSalary\")\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUV8l1eWy90u"
      },
      "source": [
        "\n",
        "La función *filter()* nos permite filtrar la información a través de condiciones. Por ejemplo, vamos a mostrar unicamente aquellos empleados que tengan un salario menor o igual a $25,000.00."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGGtrHVxq1qB",
        "outputId": "e91eaccc-6427-4671-eda9-44975d18d172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(\"EmpSalary<=25000\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO6txvqVzdZL"
      },
      "source": [
        "Como pudieron observar hay una cierta similitud de la función *filter()* con SELECT de SQL. Es por eso que se pueden utilizar consultas SQL y tratar los DataFrames como tablas o vistas de un modelo relacional. La función *createOrReplaceTempView()* registra el DataFrame como una vista temporal dentro de la sesión que puede ejecutar consutlas SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSkcljBNxiKE",
        "outputId": "9adab7f2-6517-4e23-af79-a7d035dd81c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.createOrReplaceTempView(\"empleados\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM empleados\")\n",
        "sqlDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4UHtcD20q8i"
      },
      "source": [
        "Si la vista temporal que se produce quieren que sea utilizada en multiples sesiones entonces hay que utilizar la función *createOrReplaceTempView()*. El unico detalle es que la vista quedará anclada a una base de datos llamada *global_temp*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNc4FMzG1Rln",
        "outputId": "6bc18336-4722-45e1-e8d3-8b09d3bed9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.createGlobalTempView(\"g_empleados\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM global_temp.g_empleados\")\n",
        "sqlDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ATcN_3S1162"
      },
      "source": [
        "Como mencionamos la vista perdura en otras sesiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR9qBGWh1-rz",
        "outputId": "23ed53a1-e457-4e18-e231-5ac2ec234081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           null|                 null|    40000|\n",
            "|         null|             34|                   10|    38000|\n",
            "|         null|             36|                 null|     null|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.newSession().sql(\"SELECT * FROM global_temp.g_empleados\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOw7X7R92H1a"
      },
      "source": [
        "Se puede de igual forma cambiar el nombre de multiples columnas al mismo tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vkSgApfrlzG",
        "outputId": "571a3451-d4d1-4f40-8575-63cf8d57da1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+---------------------+---------+\n",
            "|EmpName|EmpAge|Experience (in years)|EmpSalary|\n",
            "+-------+------+---------------------+---------+\n",
            "| Oliver|    31|                   10|    30000|\n",
            "|  Harry|    30|                    8|    25000|\n",
            "| George|    29|                    4|    20000|\n",
            "|   Jack|    24|                    3|    20000|\n",
            "|  Jacob|    21|                    1|    15000|\n",
            "|    Leo|    23|                    2|    18000|\n",
            "|  Oscar|  null|                 null|    40000|\n",
            "|   null|    34|                   10|    38000|\n",
            "|   null|    36|                 null|     null|\n",
            "+-------+------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Cambiamos el nombre de multiples columnas \n",
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Age of Employee\",\"EmpAge\").withColumnRenamed(\"Employee Name\",\"EmpName\")\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Rl2uG32Q_Z"
      },
      "source": [
        "Al igual que en SQL se pueden seleccionar las columnas que serán mostradas dentro de la consulta acompañando a la función *filter()* con la función *select()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGtFqXeyri3Z",
        "outputId": "aa662b04-ec8a-469b-f652-6c9a7a990c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|EmpName|EmpAge|\n",
            "+-------+------+\n",
            "|  Harry|    30|\n",
            "| George|    29|\n",
            "|   Jack|    24|\n",
            "|  Jacob|    21|\n",
            "|    Leo|    23|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(\"EmpSalary<=25000\").select(['EmpName','EmpAge']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXx1CwoD2sW1"
      },
      "source": [
        "Otra manera de filtrar la información de los registros es utilizar un estilo similar a Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOZuURvRr4HZ",
        "outputId": "b8999650-fd85-4b3d-e9a3-8a9a15d30d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|EmpName|EmpAge|\n",
            "+-------+------+\n",
            "|  Harry|    30|\n",
            "| George|    29|\n",
            "|   Jack|    24|\n",
            "|  Jacob|    21|\n",
            "|    Leo|    23|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(df_filter_pyspark['EmpSalary']<=25000).select(['EmpName','EmpAge']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPM5Da224mk"
      },
      "source": [
        "## Operadores Lógicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHT4extP4NfO"
      },
      "source": [
        "Los operadores lógicos disponibles son AND (&), OR (|) y NOT (~)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOTdAcq64fFd"
      },
      "source": [
        "Ejemplo con AND: Los empleados que su salario sea menor o igual a \\$30,000.00 y que sea mayor o igual a \\$18,000.00."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYgWyHBUsDw-",
        "outputId": "cddddf95-4bab-442d-c1a2-c8dea5517961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+---------------------+---------+\n",
            "|EmpName|EmpAge|Experience (in years)|EmpSalary|\n",
            "+-------+------+---------------------+---------+\n",
            "| Oliver|    31|                   10|    30000|\n",
            "|  Harry|    30|                    8|    25000|\n",
            "| George|    29|                    4|    20000|\n",
            "|   Jack|    24|                    3|    20000|\n",
            "|    Leo|    23|                    2|    18000|\n",
            "+-------+------+---------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n",
        "                          & (df_filter_pyspark['EmpSalary']>=18000)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjuqaJ80syOs",
        "outputId": "82d25f7d-75a8-4d93-8dcf-1f50fa264387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| Oliver|    31|           10|    30000|\n",
            "|  Harry|    30|            8|    25000|\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "|  Oscar|  null|         null|    40000|\n",
            "|   null|    34|           10|    38000|\n",
            "|   null|    36|         null|     null|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Cambiamos el nombre de la columna experiencia\n",
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Experience (in years)\",\"EmpExperience\")\n",
        "df_filter_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latXscc144pR"
      },
      "source": [
        "Ejemplo con OR: Los empleados que su salario sea menor o igual a \\$30,000.00 ó que su experiencia laboral sea mayor o igual a 3 años."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxIIaEmvsvvA",
        "outputId": "9ecb263c-e351-4160-896a-8e4dfc055d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| Oliver|    31|           10|    30000|\n",
            "|  Harry|    30|            8|    25000|\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "|   null|    34|           10|    38000|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n",
        "                          | (df_filter_pyspark['EmpExperience']>=3)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFxPQ4OL5YIR"
      },
      "source": [
        "Ejemplo NOT: Los empleandos que su edad no sea mayor o igual a 30 años."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohEM94QPs9UE",
        "outputId": "c34f1b31-1b1a-472c-cb86-e2cece2777e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_pyspark.filter(~(df_filter_pyspark['EmpAge']>=30)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikvKjBuY6e7-"
      },
      "source": [
        "# Tutorial 3: Manejo de valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "2WFOahsM6utd",
        "outputId": "e9792576-7f2e-4bd2-c3a6-856f0555153e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://869aba917921:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ValoresNulos</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6cdf30d910>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Creamos una sesión de PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "#spark.stop()\n",
        "null_spark = SparkSession.builder.appName('ValoresNulos').getOrCreate()\n",
        "null_spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5TJdLAp7ASc",
        "outputId": "18a9ef2f-382d-47dd-b855-038ff96a769c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[Employee Name: string, Age of Employee: int, Experience (in years): int, Salary (per month - $): int]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Cargamos los datos dentro de un DataFrame de la sesión\n",
        "df_null_pyspark = null_spark.read.csv('part2.csv', header = True, inferSchema = True)\n",
        "df_null_pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXstlu57QSQ",
        "outputId": "668790c4-edf9-44d2-d300-30fbffa70b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           null|                 null|                 40000|\n",
            "|         null|             34|                   10|                 38000|\n",
            "|         null|             36|                 null|                  null|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Visualizamos la información\n",
        "df_null_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAflsQi47elO",
        "outputId": "230f539b-ba3c-444b-812d-faa7f35f1855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Employee Name: string (nullable = true)\n",
            " |-- Age of Employee: integer (nullable = true)\n",
            " |-- Experience (in years): integer (nullable = true)\n",
            " |-- Salary (per month - $): integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Nuevamente vemos la estructura de la información\n",
        "# recordando que cuando tenemos nullable = true significa que esa columna permite \n",
        "# valores nulos\n",
        "df_null_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPVY4QKT728z"
      },
      "source": [
        "El función para eliminar los valores nulos dentro de la información es *na.drop()*. Esta función elimina completamente los registros que tiene algún valor nulo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk7qANkD72Z4",
        "outputId": "c0df6f4b-90ef-4690-c1ad-62fad63d8e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HULRD2Mr8WUI"
      },
      "source": [
        "Si queremos controlar el como se eliminan los registros la función tiene un parámetro llamado *how* con dos posibles valores:\n",
        "\n",
        "\n",
        "*   ALL: Elimina la tupla siempre y cuando todos los valores asociados a cada columna sean nulos.\n",
        "*   ANY: Elimina la tupla si alguno de los valores asociados a cada columns es nulo. Esta es la configuración por default.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI5INUDi9DCE",
        "outputId": "249a7b3c-6d1f-4b62-d613-f1976be24365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           null|                 null|                 40000|\n",
            "|         null|             34|                   10|                 38000|\n",
            "|         null|             36|                 null|                  null|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(how=\"all\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7EqNcvQ9G02",
        "outputId": "07ed60dd-d22e-4ae0-c15c-6dcc31a12868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(how=\"any\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-m7EXqo9L8f"
      },
      "source": [
        "Tambien hay forma de especificar el número mínimo de valores nulos aceptables con el parámetro *thresh*. En el ejemplo se puede observar que elimina solo una tupla que tenia tres valores nulos asociados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEZfXpS49XDo",
        "outputId": "c87a0a78-355a-44dd-c742-2cf9cbf4beb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           null|                 null|                 40000|\n",
            "|         null|             34|                   10|                 38000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(thresh=2).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKMI4Qmc9yji"
      },
      "source": [
        "De igual forma podemos combiar el parámetro *how* con *subset* para indicarle las columnas donde nos interesan detectar valores nulos en las tuplas y eliminarlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhma9LrN9ya0",
        "outputId": "f37e2c7b-edfa-4736-e55e-54b82acbd50a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|         null|             34|                   10|                 38000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.drop(how='any', subset=['Experience (in years)']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKkz--0i-Oyk"
      },
      "source": [
        "Podemos rellenar los valores nulos con algún valor en especifico utilizando la función *na.fill()* indicando el valor y la columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAMqYGjo-krE",
        "outputId": "bd0faaea-b7d0-48bf-883b-463ded829f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           null|                 null|                 40000|\n",
            "|    NA values|             34|                   10|                 38000|\n",
            "|    NA values|             36|                 null|                  null|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_null_pyspark.na.fill('NA values', 'Employee Name').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbXa3gu6-u4i"
      },
      "source": [
        "Otra alternativa para rellenar los valores faltantes es utilizando el método de imputación de datos utilizando la media. Para esto hay que utilizar la clase *Imputer* especificando las columnas de entrada y las de salida que se agregaran al DataFrame así como la estrategia en este caso utilizar la media. Después, se utiliza la función *fit()* y *transform()* para integrar las columnas imputadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FAlh9Sy-vBv",
        "outputId": "a5461fd6-85fd-4eff-96e0-69fffe745e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|Age of Employee_imputed|Experience (in years)_imputed|Salary (per month - $)_imputed|\n",
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "|       Oliver|             31|                   10|                 30000|                     31|                           10|                         30000|\n",
            "|        Harry|             30|                    8|                 25000|                     30|                            8|                         25000|\n",
            "|       George|             29|                    4|                 20000|                     29|                            4|                         20000|\n",
            "|         Jack|             24|                    3|                 20000|                     24|                            3|                         20000|\n",
            "|        Jacob|             21|                    1|                 15000|                     21|                            1|                         15000|\n",
            "|          Leo|             23|                    2|                 18000|                     23|                            2|                         18000|\n",
            "|        Oscar|           null|                 null|                 40000|                     28|                            5|                         40000|\n",
            "|         null|             34|                   10|                 38000|                     34|                           10|                         38000|\n",
            "|         null|             36|                 null|                  null|                     36|                            5|                         25750|\n",
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)'],\n",
        "    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",
        ").setStrategy(\"mean\")\n",
        "imputer.fit(df_null_pyspark).transform(df_null_pyspark).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_zMjiAbClef"
      },
      "source": [
        "# Tutorial 4: Manejo de DataFrames en PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "gWBdsz42Czua",
        "outputId": "5bd21d4c-f76f-463a-b21f-0890b79bfd76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3014fe41a4dd:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>DataFrame_article</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fe387e88510>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Creamos la sesión de trabajo\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "data_spark = SparkSession.builder.appName('DataFrame_article').getOrCreate()\n",
        "data_spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I1c0TjrC9Sv",
        "outputId": "0e3dbdc2-551c-423e-f81e-46a9be651eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Cargamos los datos e imprimimos la descripción del schema\n",
        "df_pyspark = data_spark.read.option('header','true').csv('/content/sample_data/california_housing_train.csv', inferSchema=True)\n",
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5q5LqAcMVM3",
        "outputId": "43ed7138-a6cc-477e-f161-b2f35070510e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Visualizamos la información\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSz7YI4wMscN"
      },
      "source": [
        "En caso de querer cambiar el tipo de dato de alguna columna lo podemos hacer con las funciones *withColumn()* y *cast()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XWt7j0x4MslB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import column\n",
        "df_pyspark=df_pyspark.withColumn(\"housing_median_age\",column(\"housing_median_age\").cast(\"int\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oubrma8MEU-"
      },
      "source": [
        "Con el atributo *dtypes* podemos saber el tipo de dato por columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QJEKDVHDHrE",
        "outputId": "06aead40-e7a1-4113-ca40-fa8a64756a85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('longitude', 'double'),\n",
              " ('latitude', 'double'),\n",
              " ('housing_median_age', 'int'),\n",
              " ('total_rooms', 'double'),\n",
              " ('total_bedrooms', 'double'),\n",
              " ('population', 'double'),\n",
              " ('households', 'double'),\n",
              " ('median_income', 'double'),\n",
              " ('median_house_value', 'double')]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pyspark.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghry7pbYN43p"
      },
      "source": [
        "Si queremos saber el nombre de las columnas utilizamos el atributo *columns*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RjGvsq_DT4k",
        "outputId": "2e912ec5-85a6-4b94-fd90-88f586b1fe7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['longitude',\n",
              " 'latitude',\n",
              " 'housing_median_age',\n",
              " 'total_rooms',\n",
              " 'total_bedrooms',\n",
              " 'population',\n",
              " 'households',\n",
              " 'median_income',\n",
              " 'median_house_value']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pyspark.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdcYuuXAOBr3"
      },
      "source": [
        "También, se puede seleccionar todos los datos de una columna en particular con la función *select()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k3Qp6F9DWVP",
        "outputId": "d9277492-ef43-4a5b-df4d-0a79ba989b33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|     5612.0|\n",
            "|     7650.0|\n",
            "|      720.0|\n",
            "|     1501.0|\n",
            "|     1454.0|\n",
            "|     1387.0|\n",
            "|     2907.0|\n",
            "|      812.0|\n",
            "|     4789.0|\n",
            "|     1497.0|\n",
            "|     3741.0|\n",
            "|     1988.0|\n",
            "|     1291.0|\n",
            "|     2478.0|\n",
            "|     1448.0|\n",
            "|     2556.0|\n",
            "|     1678.0|\n",
            "|       44.0|\n",
            "|     1388.0|\n",
            "|       97.0|\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.select('total_rooms').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5T8sf9yOUxs"
      },
      "source": [
        "O en caso de querer seleccionar varias columnas tambien se puede lograr enviando una lista con el nombre de las columnas como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JpH1i60DZVk",
        "outputId": "5cc2175b-0563-412a-9fff-caa8831689d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------------+-------------+\n",
            "|total_rooms|total_bedrooms|median_income|\n",
            "+-----------+--------------+-------------+\n",
            "|     5612.0|        1283.0|       1.4936|\n",
            "|     7650.0|        1901.0|         1.82|\n",
            "|      720.0|         174.0|       1.6509|\n",
            "|     1501.0|         337.0|       3.1917|\n",
            "|     1454.0|         326.0|        1.925|\n",
            "|     1387.0|         236.0|       3.3438|\n",
            "|     2907.0|         680.0|       2.6768|\n",
            "|      812.0|         168.0|       1.7083|\n",
            "|     4789.0|        1175.0|       2.1782|\n",
            "|     1497.0|         309.0|       2.1908|\n",
            "|     3741.0|         801.0|       2.6797|\n",
            "|     1988.0|         483.0|        1.625|\n",
            "|     1291.0|         248.0|       2.1571|\n",
            "|     2478.0|         464.0|        3.212|\n",
            "|     1448.0|         378.0|       0.8585|\n",
            "|     2556.0|         587.0|       1.6991|\n",
            "|     1678.0|         322.0|       2.9653|\n",
            "|       44.0|          33.0|       0.8571|\n",
            "|     1388.0|         386.0|       1.2049|\n",
            "|       97.0|          24.0|       1.2656|\n",
            "+-----------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.select(['total_rooms', 'total_bedrooms', 'median_income']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3KgSo5MOg6f"
      },
      "source": [
        "Si queremos saber algunas medidas de tendencia central de los datos para los análisis estadísticos se puede utilizar la función *describe()* similar a Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfKnLrhzDbua",
        "outputId": "9b64e815-034c-402d-afc9-89ab0caa09ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|summary|          longitude|          latitude|housing_median_age|      total_rooms|   total_bedrooms|        population|       households|     median_income|median_house_value|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|  count|              17000|             17000|             17000|            17000|            17000|             17000|            17000|             17000|             17000|\n",
            "|   mean|-119.56210823529375|  35.6252247058827| 28.58935294117647|2643.664411764706|539.4108235294118|1429.5739411764705|501.2219411764706| 3.883578100000021|207300.91235294117|\n",
            "| stddev| 2.0051664084260357|2.1373397946570867|12.586936981660406|2179.947071452777|421.4994515798648| 1147.852959159527|384.5208408559016|1.9081565183791036|115983.76438720895|\n",
            "|    min|            -124.35|             32.54|                 1|              2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
            "|    max|            -114.31|             41.95|                52|          37937.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE5gL9snPdsE"
      },
      "source": [
        "De igual manera se pueden agregar columnas directamente al DataFrame si se requiere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t38O8t0cDfY3",
        "outputId": "22022b1f-d06f-4c6c-cebc-89edcbab77ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|Updated_medianhousevalue|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|                133800.0|\n",
            "|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|                160200.0|\n",
            "|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|                171400.0|\n",
            "|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|                146800.0|\n",
            "|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|                131000.0|\n",
            "|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|                148000.0|\n",
            "|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|                164800.0|\n",
            "|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|                 97000.0|\n",
            "|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|                116800.0|\n",
            "|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|                 96200.0|\n",
            "|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|                173000.0|\n",
            "|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|                124000.0|\n",
            "|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|                 97200.0|\n",
            "|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|                140800.0|\n",
            "|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|                 90000.0|\n",
            "|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|                138200.0|\n",
            "|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|                189800.0|\n",
            "|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|                 50000.0|\n",
            "|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|                 88000.0|\n",
            "|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|                 55000.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark = df_pyspark.withColumn('Updated_medianhousevalue', df_pyspark['median_house_value']*2)\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHB46MbDPnmZ"
      },
      "source": [
        "De igual forma se pueden eliminar con la función *drop()*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Vp00etD_LX",
        "outputId": "b9aeb19e-925e-4435-f1d5-8ae361328005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.drop('Updated_medianhousevalue').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYc2mWGlPxFH"
      },
      "source": [
        "# Tutorial 5: Agregación y agrupamientos\n",
        "\n",
        "Agrupar los datos es una de las habilidades más esenciales cuando trabajamos con Big Data dado que estamos tratando con una gran cantidad de datos y si no somos capaces de segmentar esos datos, entonces será mucho más difícil analizarlos y usarlos para obtener información relevante\n",
        "\n",
        "La regla de oro es recordar que la función *groupBy()* y la función de agregación van de la mano, es decir, no podemos usar groupBy sin la función agregada como SUM, COUNT, AVG, MAX, MIN, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "pCMVYeyoT0dq",
        "outputId": "ca6636d8-2f48-43f1-84d6-1381ac93c473"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7b61ca1ed03b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Aggregate and GroupBy</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f19bef9b250>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark_aggregate = SparkSession.builder.appName('Aggregate and GroupBy').getOrCreate()\n",
        "spark_aggregate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8YpcNuaTtUQ",
        "outputId": "366c7abc-8df1-429d-b29a-0a928e3ffd91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------+------+\n",
            "|  Name|  Departmens|salary|\n",
            "+------+------------+------+\n",
            "|Oliver|Data Science| 10000|\n",
            "|Oliver|         IOT|  5000|\n",
            "| Johny|    Big Data|  4000|\n",
            "|Oliver|    Big Data|  4000|\n",
            "| Johny|Data Science|  3000|\n",
            "|Mathew|Data Science| 20000|\n",
            "|Mathew|         IOT| 10000|\n",
            "|Mathew|    Big Data|  5000|\n",
            "| Jacob|Data Science| 10000|\n",
            "| Jacob|    Big Data|  2000|\n",
            "+------+------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data = spark_aggregate.read.csv('part4.csv', header = True, inferSchema = True)\n",
        "spark_aggregate_data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j74wnJlET8Gk"
      },
      "source": [
        "Si llegamos a ejecutar unicamente la función *groupBy()* la respuesta será la ubicación de los datos agrupados lo cual no es relevante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9mnirSyS6O5",
        "outputId": "01a10209-dbbc-4724-febf-fde510247156"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyspark.sql.group.GroupedData at 0x7f19befb10d0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Name')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAlB-sLiUZGS"
      },
      "source": [
        "## Funciones de agregación\n",
        "\n",
        "Algunas de las funciones más comunes son:\n",
        "\n",
        "\n",
        "\n",
        "*   AVG: devuelve el conjunto de resultados agrupando la columna según el promedio del conjunto de valores.\n",
        "*   COUNT: devolverá el número total de conjuntos de valores en una columna particular correspondiente a la función groupBy.\n",
        "*   MIN: devuelve el valor mínimo o más pequeño entre todo el conjunto de valores en toda la fila.\n",
        "*   MAX: el funcionamiento y el enfoque de usar la función agregada MAX es el mismo que la función agregada MIN, solo que la principal diferencia es que devolverá el valor máximo entre el conjunto de valores en la fila.\n",
        "*   SUM: devolverá la suma de todos los valores numéricos correspondientes a la columna agrupada\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGaco-YtWYNH"
      },
      "source": [
        "Si ejecutamos la función de agrupamiento y agregación el resultado será la descripción del DataFrame por lo que si queremos visualizar la información hay que utilizar la función *show()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-35ZH9tVBHq",
        "outputId": "78f8fd95-57ea-4291-f753-f322d88ec522"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[Name: string, sum(salary): bigint]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Name').sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q54ThS92XAqX"
      },
      "source": [
        "Ejemplo: Conocer la cantidad de dinero total que le pago la compañia a cada empleado agrupando por nombre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHDQqxfGW0PD",
        "outputId": "9025dfc4-40a6-4397-b8a8-7c7cf8b0420c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----------+\n",
            "|  Name|sum(salary)|\n",
            "+------+-----------+\n",
            "| Jacob|      12000|\n",
            "| Johny|       7000|\n",
            "|Mathew|      35000|\n",
            "|Oliver|      19000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Name').sum().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyyW7WWZXHx4"
      },
      "source": [
        "Ejemplo: Conocer la cantidad de dinero total que pago cada departamento a sus empleados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5st2YW3XPIS",
        "outputId": "aeedecb6-02ca-484b-c8f6-4fd7a09d580c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----------+\n",
            "|  Departmens|sum(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Departmens').sum().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3imE2OXvXaIx"
      },
      "source": [
        "Ejemplo: Conocer el salario promedio que se le pago a los empleados por departamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdtCu_hsXnO5",
        "outputId": "d4216182-ebb9-4890-861c-6f516c9aa002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----------+\n",
            "|  Departmens|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy('Departmens').mean().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlhwGhpkXylB"
      },
      "source": [
        "Ejemplo: Saber el número de pagos que recibio cada empleado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEowM03EXywJ",
        "outputId": "173329d6-26c9-4e9e-bdba-1216e6746776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|  Name|count|\n",
            "+------+-----+\n",
            "| Jacob|    2|\n",
            "| Johny|    2|\n",
            "|Mathew|    3|\n",
            "|Oliver|    3|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark_aggregate_data.groupBy(['Name']).count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHhiL2rneKF5"
      },
      "source": [
        "# Tutorial 6: Usando ML en PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "lzkltL3aeXm-",
        "outputId": "dc1a0b13-ec4d-46f5-f4b6-c2f116b99dd3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2946620c4d7e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>EjemploML</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa6680cbf10>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "df_ml = SparkSession.builder.appName('EjemploML').getOrCreate()\n",
        "df_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tumrUfnSf8z4",
        "outputId": "6d52f831-1bb4-4f8f-bcfc-f7f455122fe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[age: int, selling_price: int, km_driven: int, mileage: double, engine: int, max_power: double, seats: int]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Cargamos la información en un DataFrame\n",
        "training_dataset  = df_ml.read.csv('UserCarDataExample.csv', header=True, inferSchema=True)\n",
        "training_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb1J2b66gLEE",
        "outputId": "a80b94b3-b47f-4f32-f07a-f5eb4bfa39c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "|age|selling_price|km_driven|mileage|engine|max_power|seats|\n",
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "|  8|       450000|   145500|   23.4|  1248|     74.0|    5|\n",
            "|  8|       370000|   120000|  21.14|  1498|   103.52|    5|\n",
            "| 16|       158000|   140000|   17.7|  1497|     78.0|    5|\n",
            "| 12|       225000|   127000|   23.0|  1396|     90.0|    5|\n",
            "| 15|       130000|   120000|   16.1|  1298|     88.2|    5|\n",
            "|  5|       440000|    45000|  20.14|  1197|    81.86|    5|\n",
            "| 15|        96000|   175000|   17.3|  1061|     57.5|    5|\n",
            "| 21|        45000|     5000|   16.1|   796|     37.0|    4|\n",
            "| 11|       350000|    90000|  23.59|  1364|     67.1|    5|\n",
            "|  9|       200000|   169000|   20.0|  1399|     68.1|    5|\n",
            "|  8|       500000|    68000|  19.01|  1461|   108.45|    5|\n",
            "| 17|        92000|   100000|   17.3|   993|     60.0|    5|\n",
            "| 13|       280000|   140000|   19.3|  1248|     73.9|    5|\n",
            "| 13|       180000|    90000|   18.9|  1061|     67.0|    5|\n",
            "|  6|       400000|    40000|  18.15|  1198|     82.0|    5|\n",
            "|  6|       778000|    70000|  24.52|  1248|     88.5|    7|\n",
            "| 10|       500000|    53000|   23.0|  1396|     90.0|    5|\n",
            "| 20|       150000|    80000|   19.7|   796|     46.3|    5|\n",
            "|  6|       680000|   100000|  22.54|  1396|    88.73|    5|\n",
            "| 11|       174000|   100000|   21.0|  1461|     64.1|    5|\n",
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Mostramos la información\n",
        "training_dataset.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H4E0wYKgOnS",
        "outputId": "64f21084-4779-4d13-c252-7655bfa0036d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- selling_price: integer (nullable = true)\n",
            " |-- km_driven: integer (nullable = true)\n",
            " |-- mileage: double (nullable = true)\n",
            " |-- engine: integer (nullable = true)\n",
            " |-- max_power: double (nullable = true)\n",
            " |-- seats: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Visualizamos el esquema de la base de datos\n",
        "training_dataset.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQkaCFvAgRL2",
        "outputId": "c3eb8ec6-2a65-42e7-bb03-1611ef7a1511"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['age',\n",
              " 'selling_price',\n",
              " 'km_driven',\n",
              " 'mileage',\n",
              " 'engine',\n",
              " 'max_power',\n",
              " 'seats']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Visualizamos el nombre de las columnas\n",
        "training_dataset.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moU5VyLK8tlJ"
      },
      "source": [
        "Para trabajar con modelos de regresión tenemos que utilizar *VectorAssembler* para convertir las variables independientes en un vector que las incluya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw-DruM-gkRm",
        "outputId": "486191a3-ab48-41d8-9ad3-640a499c25df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorAssembler_c5d093af7d0e"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "featassembler = VectorAssembler(inputCols=['age',\n",
        " 'km_driven',\n",
        " 'mileage',\n",
        " 'engine',\n",
        " 'max_power',\n",
        " 'seats'], outputCol = \"Independent Features\" )\n",
        "featassembler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j2BdYSb9LCY"
      },
      "source": [
        "Posteriormente se integran al conjunto de datos que ya estaba cargado utilizando la función *transform()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSF0ijSFgsqS",
        "outputId": "411abfbc-7868-4e76-8890-b0ebbc46be35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "|age|selling_price|km_driven|mileage|engine|max_power|seats|Independent Features|\n",
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "|  8|       450000|   145500|   23.4|  1248|     74.0|    5|[8.0,145500.0,23....|\n",
            "|  8|       370000|   120000|  21.14|  1498|   103.52|    5|[8.0,120000.0,21....|\n",
            "| 16|       158000|   140000|   17.7|  1497|     78.0|    5|[16.0,140000.0,17...|\n",
            "| 12|       225000|   127000|   23.0|  1396|     90.0|    5|[12.0,127000.0,23...|\n",
            "| 15|       130000|   120000|   16.1|  1298|     88.2|    5|[15.0,120000.0,16...|\n",
            "|  5|       440000|    45000|  20.14|  1197|    81.86|    5|[5.0,45000.0,20.1...|\n",
            "| 15|        96000|   175000|   17.3|  1061|     57.5|    5|[15.0,175000.0,17...|\n",
            "| 21|        45000|     5000|   16.1|   796|     37.0|    4|[21.0,5000.0,16.1...|\n",
            "| 11|       350000|    90000|  23.59|  1364|     67.1|    5|[11.0,90000.0,23....|\n",
            "|  9|       200000|   169000|   20.0|  1399|     68.1|    5|[9.0,169000.0,20....|\n",
            "|  8|       500000|    68000|  19.01|  1461|   108.45|    5|[8.0,68000.0,19.0...|\n",
            "| 17|        92000|   100000|   17.3|   993|     60.0|    5|[17.0,100000.0,17...|\n",
            "| 13|       280000|   140000|   19.3|  1248|     73.9|    5|[13.0,140000.0,19...|\n",
            "| 13|       180000|    90000|   18.9|  1061|     67.0|    5|[13.0,90000.0,18....|\n",
            "|  6|       400000|    40000|  18.15|  1198|     82.0|    5|[6.0,40000.0,18.1...|\n",
            "|  6|       778000|    70000|  24.52|  1248|     88.5|    7|[6.0,70000.0,24.5...|\n",
            "| 10|       500000|    53000|   23.0|  1396|     90.0|    5|[10.0,53000.0,23....|\n",
            "| 20|       150000|    80000|   19.7|   796|     46.3|    5|[20.0,80000.0,19....|\n",
            "|  6|       680000|   100000|  22.54|  1396|    88.73|    5|[6.0,100000.0,22....|\n",
            "| 11|       174000|   100000|   21.0|  1461|     64.1|    5|[11.0,100000.0,21...|\n",
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = featassembler.transform(training_dataset)\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEIplNaj9aTy"
      },
      "source": [
        "Para construir nuestro modelo de regresión debemos selecccionar la columna que integró los valores de las columnas en un vector y la columna que representa la variable dependiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkN24b3_gxBD",
        "outputId": "36aeca7a-c949-4731-b62a-e9ebe437d617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+\n",
            "|Independent features|selling_price|\n",
            "+--------------------+-------------+\n",
            "|[8.0,145500.0,23....|       450000|\n",
            "|[8.0,120000.0,21....|       370000|\n",
            "|[16.0,140000.0,17...|       158000|\n",
            "|[12.0,127000.0,23...|       225000|\n",
            "|[15.0,120000.0,16...|       130000|\n",
            "|[5.0,45000.0,20.1...|       440000|\n",
            "|[15.0,175000.0,17...|        96000|\n",
            "|[21.0,5000.0,16.1...|        45000|\n",
            "|[11.0,90000.0,23....|       350000|\n",
            "|[9.0,169000.0,20....|       200000|\n",
            "|[8.0,68000.0,19.0...|       500000|\n",
            "|[17.0,100000.0,17...|        92000|\n",
            "|[13.0,140000.0,19...|       280000|\n",
            "|[13.0,90000.0,18....|       180000|\n",
            "|[6.0,40000.0,18.1...|       400000|\n",
            "|[6.0,70000.0,24.5...|       778000|\n",
            "|[10.0,53000.0,23....|       500000|\n",
            "|[20.0,80000.0,19....|       150000|\n",
            "|[6.0,100000.0,22....|       680000|\n",
            "|[11.0,100000.0,21...|       174000|\n",
            "+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "final_data = result.select(\"Independent features\", \"selling_price\")\n",
        "final_data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXw3mdLr-ieZ"
      },
      "source": [
        "Del conjunto total de datos se puede generar un división de conjunto de datos entre entrenamiento y prueba con la función *randomSplit*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRqfuLCSg3WF"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = final_data.randomSplit([0.75, 0.25])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1enV5l9G-ul7"
      },
      "source": [
        "Ahora bien hay que importar *LinearRegression* de la biblioteca de machine learning de PySpark. Especificando cuales son la variables independientes y cual es la dependiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzyfNi_5g6Ro"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "model = LinearRegression(featuresCol = 'Independent features', labelCol='selling_price')\n",
        "model = model.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWZ7qUpPANhH"
      },
      "source": [
        "Podemos imprimir la matriz de correlación para verificar la congruencia del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_PZNczQjDUy",
        "outputId": "41b71b88-ecaa-45ae-9963-8a39ef0c9807"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/spark-3.2.2-bin-hadoop3.2/python/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.42854848, -0.32854385, -0.0182631 , -0.2265978 ,\n",
              "         0.00792303],\n",
              "       [ 0.42854848,  1.        , -0.17298035,  0.20603073, -0.03815852,\n",
              "         0.22725939],\n",
              "       [-0.32854385, -0.17298035,  1.        , -0.57640787, -0.37462089,\n",
              "        -0.45170047],\n",
              "       [-0.0182631 ,  0.20603073, -0.57640787,  1.        ,  0.70397453,\n",
              "         0.61110339],\n",
              "       [-0.2265978 , -0.03815852, -0.37462089,  0.70397453,  1.        ,\n",
              "         0.19199918],\n",
              "       [ 0.00792303,  0.22725939, -0.45170047,  0.61110339,  0.19199918,\n",
              "         1.        ]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.stat import Correlation\n",
        "\n",
        "matrix = Correlation.corr(final_data, 'Independent features')\n",
        "cor_np = matrix.collect()[0][matrix.columns[0]].toArray()\n",
        "cor_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0eiZUdrAUKW"
      },
      "source": [
        "Obtener el valor del intercepto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRPAwuMDhGsQ",
        "outputId": "9889cddb-d906-4ce4-f571-c67f5b73730c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-424866.692968382"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.intercept"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWm_ACuzAXhS"
      },
      "source": [
        "Los coeficientes por cada variable independiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmOSQXazhC4_",
        "outputId": "460e6ed0-a7b0-448e-ad72-35e42ff2a757"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DenseVector([-38232.021, -1.986, 13101.5334, 119.5839, 15872.4387, -66841.9372])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvVYUVYQAbst"
      },
      "source": [
        "Así como los p-values para determinar la transendencia de cada variable dentro del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvpGrjq1iEvM",
        "outputId": "562dd4ea-a260-430d-8a6b-453cd9f13f74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 4.748173399571343e-06,\n",
              " 0.0004702082331640156,\n",
              " 0.0,\n",
              " 4.440892098500626e-16,\n",
              " 0.00028024818997884893]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.summary.pValues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz0Mb-N_AkKw"
      },
      "source": [
        "Obtener indicadores de desempeño como la $r^2$ ajustada, dado que es un problema multivariado. Que nos sirve para indicar el porcentaje de la variabilidad de la variable dependiente explicada por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi-wb7QUifex",
        "outputId": "7ee2b17c-82b1-4ec8-e3e0-b231d2e3e351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.645674650687369"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.summary.r2adj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5rpjApHA12V"
      },
      "source": [
        "Podemos realizar predicciones para evaluar el modelo obtenido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHIihH1RhJ-b",
        "outputId": "a7eefce6-5fd3-4ce5-f351-b317c8305c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+------------------+\n",
            "|Independent features|selling_price|        prediction|\n",
            "+--------------------+-------------+------------------+\n",
            "|[2.0,1000.0,20.3,...|       500000| 638739.7452848451|\n",
            "|[2.0,1000.0,21.21...|       445000| 881864.5347799484|\n",
            "|[2.0,1000.0,21.21...|       654000| 881864.5347799484|\n",
            "|[2.0,5000.0,0.0,2...|       679000| 767836.4410321887|\n",
            "|[2.0,5000.0,13.38...|      7200000|3760255.2490451713|\n",
            "|[2.0,5000.0,17.8,...|      1900000|1366210.3748440805|\n",
            "|[2.0,5000.0,20.89...|       600000|  869728.221734992|\n",
            "|[2.0,5000.0,21.21...|       578000|   873920.71242499|\n",
            "|[2.0,5000.0,21.21...|       600000|   873920.71242499|\n",
            "|[2.0,5000.0,21.94...|       399000| 564329.2291149902|\n",
            "|[2.0,5000.0,22.05...|       350000| 289373.7299386224|\n",
            "|[2.0,5000.0,22.05...|       350000| 289373.7299386224|\n",
            "|[2.0,5500.0,26.8,...|      2125000|1568581.1389149178|\n",
            "|[2.0,7400.0,24.3,...|       925000|1022082.2744554535|\n",
            "|[2.0,10000.0,19.0...|       450000| 601299.6886728541|\n",
            "|[2.0,13000.0,21.6...|       475000| 605461.3247648876|\n",
            "|[2.0,15000.0,22.0...|       370000| 269514.1740512264|\n",
            "|[2.0,15000.0,23.8...|       500000| 920978.4078025923|\n",
            "|[2.0,16000.0,17.0...|      1650000| 2250648.221458587|\n",
            "|[2.0,25000.0,21.6...|       420000| 581629.8577000124|\n",
            "+--------------------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_result = model.evaluate(test_data)\n",
        "prediction_result.predictions.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzBuAmmiA7pk"
      },
      "source": [
        "Mostrar algunos indicadores de desempeño utiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdRto3yjhe_0",
        "outputId": "d31a95af-1673-447c-8433-83c867a5dbd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(287955.3180008317, 217524942063.13354)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_result.meanAbsoluteError, prediction_result.meanSquaredError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ4qq4PRBWK3"
      },
      "source": [
        "#Tutorial 7: Utilizando MLlib en PySpark\n",
        "\n",
        "MLlib es la biblioteca de aprendizaje automático (ML) de Spark. Su objetivo es hacer que el aprendizaje automático práctico sea escalable y fácil a un alto nivel. La biblioteca proporciona herramientas como:\n",
        "\n",
        "Algoritmos de ML: algoritmos de aprendizaje comunes como clasificación, regresión, agrupamiento y filtrado colaborativo.\n",
        "Características: extracción de características, transformación, reducción de dimensionalidad y selección\n",
        "Pipelines: herramientas para construir, evaluar y ajustar ML Pipelines\n",
        "Persistencia: guardar y cargar algoritmos, modelos y Pipelines\n",
        "Utilidades: álgebra lineal, estadística, manejo de datos, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmz6gEjCCGLB"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.tree import DecisionTree\n",
        "from pyspark.mllib.tree import DecisionTreeModel\n",
        "\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eINQssUpC729"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.util import MLUtils\n",
        "\n",
        "data = MLUtils.loadLibSVMFile(sc, 'spark-3.2.2-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_bVJzJ4YDZX"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo4frQjCFH26",
        "outputId": "55f4b9c2-0364-46ef-9eb6-f83e31986bd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[LabeledPoint(0.0, (692,[127,128,129,130,131,154,155,156,157,158,159,181,182,183,184,185,186,187,188,189,207,208,209,210,211,212,213,214,215,216,217,235,236,237,238,239,240,241,242,243,244,245,262,263,264,265,266,267,268,269,270,271,272,273,289,290,291,292,293,294,295,296,297,300,301,302,316,317,318,319,320,321,328,329,330,343,344,345,346,347,348,349,356,357,358,371,372,373,374,384,385,386,399,400,401,412,413,414,426,427,428,429,440,441,442,454,455,456,457,466,467,468,469,470,482,483,484,493,494,495,496,497,510,511,512,520,521,522,523,538,539,540,547,548,549,550,566,567,568,569,570,571,572,573,574,575,576,577,578,594,595,596,597,598,599,600,601,602,603,604,622,623,624,625,626,627,628,629,630,651,652,653,654,655,656,657],[51.0,159.0,253.0,159.0,50.0,48.0,238.0,252.0,252.0,252.0,237.0,54.0,227.0,253.0,252.0,239.0,233.0,252.0,57.0,6.0,10.0,60.0,224.0,252.0,253.0,252.0,202.0,84.0,252.0,253.0,122.0,163.0,252.0,252.0,252.0,253.0,252.0,252.0,96.0,189.0,253.0,167.0,51.0,238.0,253.0,253.0,190.0,114.0,253.0,228.0,47.0,79.0,255.0,168.0,48.0,238.0,252.0,252.0,179.0,12.0,75.0,121.0,21.0,253.0,243.0,50.0,38.0,165.0,253.0,233.0,208.0,84.0,253.0,252.0,165.0,7.0,178.0,252.0,240.0,71.0,19.0,28.0,253.0,252.0,195.0,57.0,252.0,252.0,63.0,253.0,252.0,195.0,198.0,253.0,190.0,255.0,253.0,196.0,76.0,246.0,252.0,112.0,253.0,252.0,148.0,85.0,252.0,230.0,25.0,7.0,135.0,253.0,186.0,12.0,85.0,252.0,223.0,7.0,131.0,252.0,225.0,71.0,85.0,252.0,145.0,48.0,165.0,252.0,173.0,86.0,253.0,225.0,114.0,238.0,253.0,162.0,85.0,252.0,249.0,146.0,48.0,29.0,85.0,178.0,225.0,253.0,223.0,167.0,56.0,85.0,252.0,252.0,252.0,229.0,215.0,252.0,252.0,252.0,196.0,130.0,28.0,199.0,252.0,252.0,253.0,252.0,252.0,233.0,145.0,25.0,128.0,252.0,253.0,252.0,141.0,37.0])),\n",
              " LabeledPoint(1.0, (692,[158,159,160,161,185,186,187,188,189,213,214,215,216,217,240,241,242,243,244,245,267,268,269,270,271,295,296,297,298,322,323,324,325,326,349,350,351,352,353,377,378,379,380,381,404,405,406,407,408,431,432,433,434,435,459,460,461,462,463,486,487,488,489,490,514,515,516,517,518,542,543,544,545,569,570,571,572,573,596,597,598,599,600,601,624,625,626,627,652,653,654,655,680,681,682,683],[124.0,253.0,255.0,63.0,96.0,244.0,251.0,253.0,62.0,127.0,251.0,251.0,253.0,62.0,68.0,236.0,251.0,211.0,31.0,8.0,60.0,228.0,251.0,251.0,94.0,155.0,253.0,253.0,189.0,20.0,253.0,251.0,235.0,66.0,32.0,205.0,253.0,251.0,126.0,104.0,251.0,253.0,184.0,15.0,80.0,240.0,251.0,193.0,23.0,32.0,253.0,253.0,253.0,159.0,151.0,251.0,251.0,251.0,39.0,48.0,221.0,251.0,251.0,172.0,234.0,251.0,251.0,196.0,12.0,253.0,251.0,251.0,89.0,159.0,255.0,253.0,253.0,31.0,48.0,228.0,253.0,247.0,140.0,8.0,64.0,251.0,253.0,220.0,64.0,251.0,253.0,220.0,24.0,193.0,253.0,220.0])),\n",
              " LabeledPoint(1.0, (692,[124,125,126,127,151,152,153,154,155,179,180,181,182,183,208,209,210,211,235,236,237,238,239,263,264,265,266,267,268,292,293,294,295,296,321,322,323,324,349,350,351,352,377,378,379,380,405,406,407,408,433,434,435,436,461,462,463,464,489,490,491,492,493,517,518,519,520,521,545,546,547,548,549,574,575,576,577,578,602,603,604,605,606,630,631,632,633,634,658,659,660,661,662],[145.0,255.0,211.0,31.0,32.0,237.0,253.0,252.0,71.0,11.0,175.0,253.0,252.0,71.0,144.0,253.0,252.0,71.0,16.0,191.0,253.0,252.0,71.0,26.0,221.0,253.0,252.0,124.0,31.0,125.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,255.0,253.0,253.0,108.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,255.0,253.0,253.0,170.0,253.0,252.0,252.0,252.0,42.0,149.0,252.0,252.0,252.0,144.0,109.0,252.0,252.0,252.0,144.0,218.0,253.0,253.0,255.0,35.0,175.0,252.0,252.0,253.0,35.0,73.0,252.0,252.0,253.0,35.0,31.0,211.0,252.0,253.0,35.0])),\n",
              " LabeledPoint(1.0, (692,[152,153,154,180,181,182,183,208,209,210,211,236,237,238,239,264,265,266,267,292,293,294,295,320,321,322,323,349,350,351,377,378,379,405,406,407,433,434,435,461,462,463,489,490,491,492,517,518,519,520,546,547,548,574,575,576,602,603,604,630,631,632,658,659,660,686,687,688],[5.0,63.0,197.0,20.0,254.0,230.0,24.0,20.0,254.0,254.0,48.0,20.0,254.0,255.0,48.0,20.0,254.0,254.0,57.0,20.0,254.0,254.0,108.0,16.0,239.0,254.0,143.0,178.0,254.0,143.0,178.0,254.0,143.0,178.0,254.0,162.0,178.0,254.0,240.0,113.0,254.0,240.0,83.0,254.0,245.0,31.0,79.0,254.0,246.0,38.0,214.0,254.0,150.0,144.0,241.0,8.0,144.0,240.0,2.0,144.0,254.0,82.0,230.0,247.0,40.0,168.0,209.0,31.0])),\n",
              " LabeledPoint(1.0, (692,[151,152,153,154,179,180,181,182,208,209,210,236,237,238,264,265,266,267,292,293,294,295,320,321,322,323,348,349,350,351,376,377,378,379,404,405,406,407,432,433,434,435,460,461,462,463,488,489,490,491,516,517,518,519,544,545,546,547,572,573,574,575,600,601,602,603,629,630,631,657,658,659,685,686,687],[1.0,168.0,242.0,28.0,10.0,228.0,254.0,100.0,190.0,254.0,122.0,83.0,254.0,162.0,29.0,254.0,248.0,25.0,29.0,255.0,254.0,103.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,255.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,63.0,29.0,254.0,254.0,28.0,29.0,254.0,254.0,28.0,29.0,254.0,254.0,35.0,29.0,254.0,254.0,109.0,6.0,212.0,254.0,109.0,203.0,254.0,178.0,155.0,254.0,190.0,32.0,199.0,104.0])),\n",
              " LabeledPoint(0.0, (692,[129,130,131,132,156,157,158,159,160,161,162,183,184,185,186,187,188,189,190,208,209,210,211,212,213,214,215,216,217,218,235,236,237,238,239,240,241,242,243,244,245,246,262,263,264,265,266,267,268,269,270,271,272,273,274,289,290,291,292,293,294,295,296,297,298,299,300,301,302,316,317,318,319,320,322,323,324,325,327,328,329,330,343,344,345,346,347,348,350,351,352,353,355,356,357,358,371,372,373,374,378,379,384,385,386,398,399,400,412,413,414,425,426,427,428,439,440,441,442,453,454,455,456,467,468,469,470,481,482,483,484,494,495,496,497,498,509,510,511,512,521,522,523,524,525,537,538,539,540,547,548,549,550,551,552,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,594,595,596,597,598,599,600,601,602,603,604,605,623,624,625,626,627,628,629,630,631,632,653,654,655,656,657,658],[64.0,253.0,255.0,63.0,96.0,205.0,251.0,253.0,205.0,111.0,4.0,96.0,189.0,251.0,251.0,253.0,251.0,251.0,31.0,16.0,64.0,223.0,244.0,251.0,251.0,211.0,213.0,251.0,251.0,31.0,80.0,181.0,251.0,253.0,251.0,251.0,251.0,94.0,96.0,251.0,251.0,31.0,92.0,253.0,253.0,253.0,255.0,253.0,253.0,253.0,95.0,96.0,253.0,253.0,31.0,92.0,236.0,251.0,243.0,220.0,233.0,251.0,251.0,243.0,82.0,96.0,251.0,251.0,31.0,80.0,253.0,251.0,251.0,188.0,96.0,251.0,251.0,109.0,96.0,251.0,251.0,31.0,96.0,240.0,253.0,243.0,188.0,42.0,96.0,204.0,109.0,4.0,12.0,197.0,251.0,31.0,221.0,251.0,253.0,121.0,36.0,23.0,190.0,251.0,31.0,48.0,234.0,253.0,191.0,253.0,31.0,44.0,221.0,251.0,251.0,12.0,197.0,251.0,31.0,190.0,251.0,251.0,251.0,96.0,251.0,251.0,31.0,190.0,251.0,251.0,113.0,40.0,234.0,251.0,219.0,23.0,190.0,251.0,251.0,94.0,40.0,217.0,253.0,231.0,47.0,191.0,253.0,253.0,253.0,12.0,174.0,253.0,253.0,219.0,39.0,67.0,236.0,251.0,251.0,191.0,190.0,111.0,72.0,190.0,191.0,197.0,251.0,243.0,121.0,39.0,63.0,236.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,188.0,94.0,27.0,129.0,253.0,251.0,251.0,251.0,251.0,229.0,168.0,15.0,95.0,212.0,251.0,211.0,94.0,59.0])),\n",
              " LabeledPoint(1.0, (692,[158,159,160,185,186,187,188,189,212,213,214,215,216,217,240,241,242,243,244,267,268,269,270,271,272,295,296,297,298,299,323,324,325,326,350,351,352,353,354,377,378,379,380,381,404,405,406,407,408,432,433,434,435,436,459,460,461,462,463,486,487,488,489,490,513,514,515,516,517,541,542,543,544,545,569,570,571,572,573,597,598,599,600,624,625,626,627,628,652,653,654,655,681,682,683],[121.0,254.0,136.0,13.0,230.0,253.0,248.0,99.0,4.0,118.0,253.0,253.0,225.0,42.0,61.0,253.0,253.0,253.0,74.0,32.0,206.0,253.0,253.0,186.0,9.0,211.0,253.0,253.0,239.0,69.0,254.0,253.0,253.0,133.0,142.0,255.0,253.0,186.0,8.0,149.0,229.0,254.0,207.0,21.0,54.0,229.0,253.0,254.0,105.0,152.0,254.0,254.0,213.0,26.0,112.0,251.0,253.0,253.0,26.0,29.0,212.0,253.0,250.0,149.0,36.0,214.0,253.0,253.0,137.0,75.0,253.0,253.0,253.0,59.0,93.0,253.0,253.0,189.0,17.0,224.0,253.0,253.0,84.0,43.0,235.0,253.0,126.0,1.0,99.0,248.0,253.0,119.0,225.0,235.0,49.0])),\n",
              " LabeledPoint(1.0, (692,[99,100,101,127,128,129,130,154,155,156,157,158,182,183,184,185,186,209,210,211,212,213,237,238,239,240,241,264,265,266,267,268,269,291,292,293,294,295,296,297,314,315,316,317,318,319,320,321,322,323,324,325,342,343,344,345,346,347,348,349,350,351,352,353,371,372,373,374,378,379,380,381,406,407,408,409,435,436,437,463,464,465,491,492,493,514,515,516,517,518,519,520,521,522,523,524,525,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,594,595,596,597,598,599,600,622,623,624,625],[166.0,222.0,55.0,197.0,254.0,218.0,5.0,29.0,249.0,254.0,254.0,9.0,45.0,254.0,254.0,174.0,2.0,4.0,164.0,254.0,254.0,85.0,146.0,254.0,254.0,254.0,85.0,101.0,245.0,254.0,254.0,254.0,85.0,97.0,248.0,254.0,204.0,254.0,254.0,85.0,12.0,59.0,98.0,151.0,237.0,254.0,254.0,109.0,35.0,254.0,254.0,85.0,41.0,216.0,254.0,254.0,239.0,153.0,37.0,4.0,32.0,254.0,254.0,85.0,7.0,44.0,44.0,30.0,32.0,254.0,254.0,96.0,19.0,230.0,254.0,174.0,197.0,254.0,110.0,197.0,254.0,85.0,197.0,253.0,63.0,37.0,54.0,54.0,45.0,26.0,84.0,221.0,84.0,21.0,31.0,162.0,78.0,6.0,41.0,141.0,244.0,254.0,254.0,248.0,236.0,254.0,254.0,254.0,233.0,239.0,254.0,138.0,23.0,167.0,254.0,254.0,254.0,254.0,229.0,228.0,185.0,138.0,138.0,138.0,138.0,138.0,138.0,44.0,113.0,254.0,254.0,254.0,179.0,64.0,5.0,32.0,209.0,183.0,97.0])),\n",
              " LabeledPoint(0.0, (692,[154,155,156,157,158,159,182,183,184,185,186,187,188,189,208,209,210,211,212,213,214,215,216,217,236,237,238,239,240,241,242,243,244,245,264,265,266,267,268,269,270,271,272,273,290,291,292,293,294,295,298,299,300,301,318,319,320,321,322,326,327,328,329,346,347,348,349,350,353,354,355,356,357,374,375,376,377,378,381,382,383,384,385,402,403,404,405,406,409,410,411,412,413,429,430,431,432,437,438,439,440,456,457,458,459,460,464,465,466,467,468,484,485,486,487,488,491,492,493,494,495,512,513,514,515,516,519,520,521,522,523,540,541,542,543,544,546,547,548,549,550,551,568,569,570,571,572,573,574,575,576,577,596,597,598,599,600,601,602,603,604,605,624,625,626,627,628,629,630,631,632,633,653,654,655,656,657,658,682,683,684,685,686],[53.0,255.0,253.0,253.0,253.0,124.0,180.0,253.0,251.0,251.0,251.0,251.0,145.0,62.0,32.0,217.0,241.0,253.0,251.0,251.0,251.0,251.0,253.0,107.0,37.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,107.0,166.0,251.0,251.0,253.0,251.0,96.0,148.0,251.0,253.0,107.0,73.0,253.0,253.0,253.0,253.0,130.0,110.0,253.0,255.0,108.0,73.0,251.0,251.0,251.0,251.0,109.0,251.0,253.0,107.0,202.0,251.0,251.0,251.0,225.0,6.0,129.0,251.0,253.0,107.0,150.0,251.0,251.0,251.0,71.0,115.0,251.0,251.0,253.0,107.0,253.0,251.0,251.0,173.0,20.0,217.0,251.0,251.0,253.0,107.0,182.0,255.0,253.0,216.0,218.0,253.0,253.0,182.0,63.0,221.0,253.0,251.0,215.0,84.0,236.0,251.0,251.0,77.0,109.0,251.0,253.0,251.0,215.0,11.0,160.0,251.0,251.0,96.0,109.0,251.0,253.0,251.0,137.0,150.0,251.0,251.0,251.0,71.0,109.0,251.0,253.0,251.0,35.0,130.0,253.0,251.0,251.0,173.0,20.0,110.0,253.0,255.0,253.0,98.0,150.0,253.0,255.0,253.0,164.0,109.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,35.0,93.0,241.0,253.0,251.0,251.0,251.0,251.0,216.0,112.0,5.0,103.0,253.0,251.0,251.0,251.0,251.0,124.0,251.0,225.0,71.0,71.0])),\n",
              " LabeledPoint(0.0, (692,[127,128,129,130,131,155,156,157,158,159,181,182,183,184,185,186,187,209,210,211,212,213,214,215,216,237,238,239,240,241,242,243,244,245,263,264,265,266,267,268,269,270,271,272,273,291,292,293,294,295,296,297,298,299,300,301,302,317,318,319,320,321,322,323,324,325,326,327,328,329,330,344,345,346,347,348,349,353,354,355,356,357,358,372,373,374,375,376,377,381,382,383,384,385,386,399,400,401,402,403,404,409,410,411,412,413,414,427,428,429,430,431,437,438,439,440,441,455,456,457,458,459,460,465,466,467,468,483,484,485,486,487,488,491,492,493,494,495,496,511,512,513,514,515,519,520,521,522,523,539,540,541,542,543,544,545,546,547,548,549,550,567,568,569,570,571,572,573,574,575,576,577,578,595,596,597,598,599,600,601,602,603,604,605,623,624,625,626,627,628,629,630,631,652,653,654,655,656,657,658],[73.0,253.0,227.0,73.0,21.0,73.0,251.0,251.0,251.0,174.0,16.0,166.0,228.0,251.0,251.0,251.0,122.0,62.0,220.0,253.0,251.0,251.0,251.0,251.0,79.0,79.0,231.0,253.0,251.0,251.0,251.0,251.0,232.0,77.0,145.0,253.0,253.0,253.0,255.0,253.0,253.0,253.0,253.0,255.0,108.0,144.0,251.0,251.0,251.0,253.0,168.0,107.0,169.0,251.0,253.0,189.0,20.0,27.0,89.0,236.0,251.0,235.0,215.0,164.0,15.0,6.0,129.0,251.0,253.0,251.0,35.0,47.0,211.0,253.0,251.0,251.0,142.0,37.0,251.0,251.0,253.0,251.0,35.0,109.0,251.0,253.0,251.0,251.0,142.0,11.0,148.0,251.0,253.0,251.0,164.0,11.0,150.0,253.0,255.0,211.0,25.0,11.0,150.0,253.0,255.0,211.0,25.0,140.0,251.0,251.0,253.0,107.0,37.0,251.0,251.0,211.0,46.0,190.0,251.0,251.0,253.0,128.0,5.0,37.0,251.0,251.0,51.0,115.0,251.0,251.0,253.0,188.0,20.0,32.0,109.0,129.0,251.0,173.0,103.0,217.0,251.0,251.0,201.0,30.0,73.0,251.0,251.0,251.0,71.0,166.0,253.0,253.0,255.0,149.0,73.0,150.0,253.0,255.0,253.0,253.0,143.0,140.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,230.0,61.0,190.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,242.0,215.0,55.0,21.0,189.0,251.0,253.0,251.0,251.0,251.0,173.0,103.0,31.0,200.0,253.0,251.0,96.0,71.0,20.0]))]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEw7hMHsatv5"
      },
      "outputs": [],
      "source": [
        "numClasses = 2\n",
        "categoricalFeaturesInfo = {}\n",
        "impurity = \"gini\"\n",
        "\n",
        "model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n",
        "  impurity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmTnplvuETu_",
        "outputId": "56d04da0-0075-4703-bad5-f66105f9bd1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error = 0.03225806451612903\n",
            "Learned classification tree model:\n",
            "DecisionTreeModel classifier of depth 2 with 5 nodes\n",
            "  If (feature 406 <= 126.5)\n",
            "   If (feature 100 <= 193.5)\n",
            "    Predict: 0.0\n",
            "   Else (feature 100 > 193.5)\n",
            "    Predict: 1.0\n",
            "  Else (feature 406 > 126.5)\n",
            "   Predict: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(testData.map(lambda x: x.features))\n",
        "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
        "testErr = labelsAndPredictions.filter(\n",
        "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
        "print('Test Error = ' + str(testErr))\n",
        "print('Learned classification tree model:')\n",
        "print(model.toDebugString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od6iDkJhIVm8"
      },
      "outputs": [],
      "source": [
        "model.save(sc, \"myDecisionTreeClassificationModel.dt\")\n",
        "sameModel = DecisionTreeModel.load(sc, \"myDecisionTreeClassificationModel.dt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h-buZtUBtnOp",
        "mr5GDyV93GOi",
        "FlPM5Da224mk",
        "ikvKjBuY6e7-",
        "7_zMjiAbClef",
        "AAlB-sLiUZGS"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('DeepLearning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5d9694dd730a9116c8584850bebaa0ec817f91f103289d776c1b803b280dbfd9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
